seed: -1                # Training seed (if negative -> sample)
num_updates: 30         # Number of training steps (entire PPO cycles)
trainer_period: 5       # Interval for one training repetition to progress until switching to the next training
n_startup_trials: 5
n_warmup_steps: 500

categorical:
  advantage_normalization: ["no", "batch", "minibatch"]
  embed_dim: [128,  256, 384]
  learning_rate: [2.5e-4, 3.0e-4, 3.5e-4,]
  max_grad_norm: [0.25, 0.5, 0.75]
  num_heads: [4, 8]
  memory_length: [20, 40, 60, 80, 100, 119]