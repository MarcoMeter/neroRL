# This is an exemplary configuration to tune hyperparameters via a grid search.
# Every parameter of a regular training configuration can be used.
# Decay schedules have to be treated differently!
# For single hyperparameters, start off with a dictionary called hyperparameters.
# Inside that dictionary, specify the key of the desired hyperparameter and add a list of value choices.
# Decay schedules have to be specified by a seperate dictionary like seen below.

# Finally, the grid search algorithm will generate all parameter combinations among each entry and each choice.
# For each combination, a new config file is created that sources the other values from the original training config.
# Be aware! Some parameter combinations could cause undesired side effects.
# Like providing different environment names and types would conflict (e.g. type: Minigrid and name: /UnityBuilds/ObstacleTower).

# Example: Tune a few hyperparameters and decay schedules
hyperparameters:
  worker-steps: [64, 128]
  num-workers: [8, 16]

learning_rate_schedule:
  initial: [3.0e-3, 1.0e-4]
  final: [1.0e-5, 1.0e-6]

beta_schedule:
  initial: [0.01, 0.001, 0.001]
  final: [0.0001] # As we are using decaying schedules, these choices should not be greater than the initial values.