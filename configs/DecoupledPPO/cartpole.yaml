# https://github.com/openai/gym

environment:
  type: "CartPole"
  name: "CartPole-v0"
  frame_skip: 1
  last_action_to_obs: False
  last_reward_to_obs: False
  obs_stacks: 1
  reset_params:
    # Whether to mask the velocity of the cart and the tip of the pole
    mask-velocity: True

model:
  load_model: False
  model_path: "./checkpoints/cartpole_decoupled/20210831-141705_2/cartpole_decoupled-199.pt"
  checkpoint_interval: 25
  activation: "relu"
  encoder: "cnn"
  vec_encoder: "linear"
  num_vec_encoder_units: 128
  hidden_layer: "default"
  num_hidden_layers: 1
  num_hidden_units: 512
  recurrence:
    layer_type: "gru"
    sequence_length: 16
    hidden_state_size: 128
    hidden_state_init: "zero"
    reset_hidden_state: False
    residual: False

evaluation:
  evaluate: False
  n_workers: 3
  seeds: [1001, 1002, 1003, 1004, 1005]
  interval: 50

sampler:
  type: "TrajectorySampler"
  n_workers: 16
  worker_steps: 256

trainer:
  algorithm: "DecoupledPPO"
  DAAC:
    adv_coefficient: 0.25
  resume_at: 0
  gamma: 0.99
  lamda: 0.95
  updates: 200
  policy_epochs: 4
  n_policy_mini_batches: 4
  value_epochs: 9
  n_value_mini_batches: 2
  value_update_interval: 1
  max_policy_grad_norm: 0.5
  max_value_grad_norm: 0.5
  run_threaded: True
  policy_learning_rate_schedule:
    initial: 1.0e-4
    final: 3.0e-4
    power: 1.0
    max_decay_steps: 200
  value_learning_rate_schedule:
    initial: 1.0e-4
    final: 1.0e-4
    power: 1.0
    max_decay_steps: 200
  beta_schedule:
    initial: 0.00001
    final: 0.000001
    power: 1.0
    max_decay_steps: 50
  policy_clip_range_schedule:
    initial: 0.2
    final: 0.2
    power: 1.0
    max_decay_steps: 200
  value_clip_range_schedule:
    initial: 0.2
    final: 0.2
    power: 1.0
    max_decay_steps: 200