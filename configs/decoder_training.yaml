environment:
  type: "MemoryGym"
  name: "SearingSpotlights-v0"
  frame_skip: 1
  last_action_to_obs: False
  last_reward_to_obs: False
  obs_stacks: 1
  grayscale: False
  resize_vis_obs: [84, 84]
  reset_params:
    start-seed: 0
    num-seeds: 100000
    max_steps: 256
    initial_spawns: 4
    num_spawns: 30
    initial_spawn_interval: 30
    spawn_interval_threshold: 10
    spawn_interval_decay: 0.95
    spot_min_radius: 7.5
    spot_max_radius: 13.75
    spot_min_speed: 0.0025
    spot_max_speed: 0.0075
    spot_damage: 1.0
    visual_feedback: True
    black_background: False
    hide_chessboard: False
    light_dim_off_duration: 6
    light_threshold: 255
    num_coins: [1]
    coin_scale: 0.375
    coins_visible: False
    use_exit: True
    exit_visible: False
    exit_scale: 0.5
    agent_speed: 3.0
    agent_health: 5
    agent_scale: 0.25
    agent_visible: False
    sample_agent_position: True
    show_last_action: True
    show_last_positive_reward: True
    reward_inside_spotlight: 0.0
    reward_outside_spotlight: 0.0
    reward_death: 0.0
    reward_exit: 1.0
    reward_max_steps: 0.0
    reward_coin: 0.25

model:
  load_model: True
  model_path: "./trxl-20000.pt"
  checkpoint_interval: 500
  activation: "relu"
  vis_encoder: "cnn"
  vec_encoder_layer: "linear"
  num_vec_encoder_units: 128
  hidden_layer: "default"
  num_hidden_layers: 1
  num_hidden_units: 384
  transformer:
    num_blocks: 3
    embed_dim: 384
    num_heads: 4
    memory_length: 256
    positional_encoding: "absolute" # options: "" "relative" "absolute" "learned"
    layer_norm: "pre" # options: "", "pre", "post"
    init_weights: "xavier" # options: "xavier" "orthogonal" "tfixup" "kaiming"
    gtrxl: False
    gtrxl_bias: 0.0
    gtrxl_swap: False
  obs_decoder:
    # Whether to attach the decoder to the cnn or the memory
    attach_to: "memory" # "memory"
    # Whether to detach the input to the decoder from the computational graph
    detach_gradient: True

sampler:
  n_workers: 16
  worker_steps: 256

trainer:
  algorithm: "DecoderTrainer"
  resume_at: 0
  updates: 30
  epochs: 1
  n_mini_batches: 8
  max_grad_norm: 1.0
  learning_rate_schedule:
    initial: 0.001
    final: 0.00001
    power: 1.0
    max_decay_steps: 100