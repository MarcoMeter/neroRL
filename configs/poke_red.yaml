environment:
  type: "PokeRed"
  name: "./neroRL/environments/poke_red/PokemonRed.gb"
  frame_skip: 1
  last_action_to_obs: False
  last_reward_to_obs: False
  obs_stacks: 1
  grayscale: False
  resize_vis_obs: [128, 40]
  reset_params:
    start-seed: 0
    num-seeds: 1
    initial-state: "./neroRL/environments/poke_red/has_pokedex_nballs.state"
    max-steps: 20

model:
  load_model: False
  model_path: ""
  checkpoint_interval: 200
  activation: "relu"
  vis_encoder: "cnn"
  hidden_layer: "default"
  num_hidden_layers: 1
  num_hidden_units: 512
  # recurrence:
  #   layer_type: "gru"
  #   num_layers: 1
  #   sequence_length: -1
  #   hidden_state_size: 512
  #   hidden_state_init: "zero"
  #   reset_hidden_state: True
  #   residual: False
  #   embed: True

evaluation:
  evaluate: False
  n_workers: 3
  seeds:
    start-seed: 100000
    num-seeds: 10
  interval: 200

sampler:
  n_workers: 32
  worker_steps: 1024

trainer:
  algorithm: "PPO"
  resume_at: 0
  gamma: 0.998
  lamda: 0.95
  updates: 50000
  epochs: 3
  n_mini_batches: 8
  value_coefficient: 0.5
  max_grad_norm: 0.5
  advantage_normalization: "minibatch"
  learning_rate_schedule:
    initial: 3.0e-4
    final: 3.0e-4
    power: 1.0
    max_decay_steps: 10000
  beta_schedule:
    initial: 0.0
    final: 0.0
    power: 1.0
    max_decay_steps: 10000
  clip_range_schedule:
    initial: 0.2
    final: 0.2
    power: 1.0
    max_decay_steps: 10000